{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e50bfe-edb9-4932-bf43-39f047bf36d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2 \n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "from models import build_model, build_model_hierINTR\n",
    "import datasets.transforms as T\n",
    "from datasets import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac39b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Set transformer detector', add_help=False)\n",
    "    parser.add_argument('--lr_backbone', default=1.00e-5, type=float)\n",
    "    parser.add_argument('--batch_size', default=1, type=int, choices=[1])\n",
    "\n",
    "    # * Backbone\n",
    "    parser.add_argument('--backbone', default='resnet50', type=str,\n",
    "                        help=\"Name of the convolutional backbone to use\")\n",
    "    parser.add_argument('--dilation', action='store_true',\n",
    "                        help=\"If true, we replace stride with dilation in the last convolutional block (DC5)\")\n",
    "    parser.add_argument('--position_embedding', default='sine', type=str, choices=('sine', 'learned'),\n",
    "                        help=\"Type of positional embedding to use on top of the image features\")\n",
    "    parser.add_argument('--resume', default='path/to/intr_checkpoint_cub_detr_r50.pth',\n",
    "                        help='resume from checkpoint')\n",
    "    \n",
    "    # * Transformer\n",
    "    parser.add_argument('--enc_layers', default=6, type=int,\n",
    "                        help=\"Number of encoding layers in the transformer\")\n",
    "    parser.add_argument('--dec_layers', default=6, type=int,\n",
    "                        help=\"Number of decoding layers in the transformer\")\n",
    "    parser.add_argument('--dim_feedforward', default=2048, type=int,\n",
    "                        help=\"Intermediate size of the feedforward layers in the transformer blocks\")\n",
    "    parser.add_argument('--hidden_dim', default=256, type=int,\n",
    "                        help=\"Size of the embeddings (dimension of the transformer)\")\n",
    "    parser.add_argument('--dropout', default=0.1, type=float,\n",
    "                        help=\"Dropout applied in the transformer\") #default=0.1\n",
    "    parser.add_argument('--nheads', default=8, type=int,\n",
    "                        help=\"Number of attention heads inside the transformer's attentions\")\n",
    "    parser.add_argument('--num_queries', default=200, type=int,\n",
    "                        help=\"Number of query slots\")\n",
    "    parser.add_argument('--pre_norm', action='store_true')\n",
    "\n",
    "    # # * Dataset parameters\n",
    "    parser.add_argument('--dataset_name', default='cub') \n",
    "    parser.add_argument('--dataset_path', default='/path/to/datasets', type=str) \n",
    "    parser.add_argument('--test', default=\"val\", type=str, choices=[\"val\", \"test\"])\n",
    "\n",
    "    # * Device parameters\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "\n",
    "    # Phylogeny parameters\n",
    "    parser.add_argument(\"--phylo_config\", type=str, default=None, \n",
    "                        help='path to the yaml file containing \"phylogeny_path\" and \"phyloDistances_string\"') # \"./configs/cub27_phylogeny.yaml\"\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de29cac8-84f7-4464-b006-cf99e2c907ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean_std = {\n",
    "    \"cub\": (\n",
    "        torch.tensor([0.485, 0.456, 0.406]),\n",
    "        torch.tensor([0.229, 0.224, 0.225]),\n",
    "    ),\n",
    "}\n",
    "\n",
    "class SingleImageDataset:\n",
    "    def __init__(self, image_path, transform=None):\n",
    "        self.image_path = image_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_path).convert('RGB')\n",
    "\n",
    "        target = {}\n",
    "        target[\"file_name\"] = [str(self.image_path)]\n",
    "        target[\"image_label\"] = torch.tensor([0000], dtype=torch.int64)  # Set the target label as needed\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img, target = self.transform(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1  \n",
    "\n",
    "def make_transforms():\n",
    "    mean, std = data_mean_std[\"cub\"]\n",
    "\n",
    "    normalize = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ])\n",
    "    return T.Compose([\n",
    "        T.RandomResize([800], max_size=1333),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "def build_single_image_dataset(image_path):\n",
    "    transform = make_transforms()\n",
    "    dataset = SingleImageDataset(image_path=image_path, transform=transform)\n",
    "    return dataset\n",
    "\n",
    "def image_preprocessing(image_path):\n",
    "    single_image_dataset = build_single_image_dataset(image_path)\n",
    "    sampler_val = torch.utils.data.SequentialSampler(single_image_dataset)\n",
    "    data_loader_val = DataLoader(single_image_dataset, args.batch_size, sampler=sampler_val,\n",
    "                                 drop_last=False, collate_fn=utils.collate_fn, num_workers=1) \n",
    "    return data_loader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea43f215-9327-46ee-a623-fa10570ebc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args, model):\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92960ce5-a3dd-4bbf-aa82-6612130db9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predicted_class(output, topk=(1,)):\n",
    "    query_logits = output['query_logits']\n",
    "    batch_size = query_logits.size(0)\n",
    "    \n",
    "    maxk = min(max(topk), query_logits.size(1))\n",
    "    _, pred = query_logits.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e41e40-38f2-40da-aa0d-79ec5bf95b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(number, filename=\"demo_image/classes.txt\"):\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\" \", 1)\n",
    "        if parts[0] == str(number):\n",
    "            class_name = parts[1]\n",
    "            break\n",
    "    else:\n",
    "        return f\"No class found for number {number}\"\n",
    "\n",
    "    class_name_parts = class_name.split(\".\")\n",
    "    modified_name = \" \".join(part.capitalize() for part in class_name_parts[1].split(\"_\"))\n",
    "\n",
    "    return modified_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b259b97d-ca36-4b89-a24b-2b9876616464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperImposeHeatmap(attention, input_image):\n",
    "    alpha=0.5\n",
    "    avg_heatmap_resized = cv2.resize(attention, (input_image.shape[1], input_image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "    avg_normalized_heatmap = (avg_heatmap_resized - np.min(avg_heatmap_resized)) / (np.max(avg_heatmap_resized) - np.min(avg_heatmap_resized))\n",
    "    heatmap = (avg_normalized_heatmap * 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.medianBlur(heatmap,15)\n",
    "    heatmap =  cv2.GaussianBlur(heatmap, (15, 15), 0)\n",
    "    result = (input_image *alpha  + heatmap * (1-alpha)).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "# def get_heatmap(latent_activation, input_image, constant_color_scale=False):\n",
    "#     image_a = latent_activation.cpu().numpy()\n",
    "#     image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "#     reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "#     if constant_color_scale:\n",
    "#         reshaped_image_a = np.concatenate((reshaped_image_a, np.zeros((reshaped_image_a.shape[1], 1)), np.ones((reshaped_image_a.shape[1], 1))*255), axis=1)\n",
    "    \n",
    "#     normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "#     heatmap_colormap = plt.get_cmap('jet')\n",
    "#     heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "\n",
    "#     if constant_color_scale:\n",
    "#         heatmap_colored = heatmap_colored[:, :-2]\n",
    "    \n",
    "#     heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "#     image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "#     image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "#     result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "#     return np.array(result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b39c060-1170-4802-933e-d53465cebf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pdb\n",
    "\n",
    "def visualization(args, image_path, query_index, attention_scores, encoder_output):\n",
    "\n",
    "    attention_score = attention_scores[5, :, :, :, :] # sixth layer of the decoder\n",
    "    attention_score_pred_query = attention_score[:, :, query_index, :] # query corresponding to predicted class \n",
    "\n",
    "    # Load and resize the original image\n",
    "    input_image = cv2.imread(image_path)\n",
    "    input_image = cv2.resize(input_image, (0, 0), fx=0.8, fy=0.8)\n",
    "\n",
    "    # Create a subplot grid for the original image and visualizations\n",
    "    num_heads = attention_score_pred_query.shape[1] + 1  \n",
    "    rows = 1\n",
    "    cols = num_heads // rows\n",
    "\n",
    "    # Plot the original image\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "    axes[0].imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for head_index in range(attention_score_pred_query.shape[1]):\n",
    "        heatmap_head = attention_score_pred_query[:, head_index, :].reshape(encoder_output.shape[2], encoder_output.shape[3]).detach().cpu().numpy()\n",
    "        pdb.set_trace()\n",
    "        result = SuperImposeHeatmap(heatmap_head, input_image) # heatmap_head-><class 'numpy.ndarray'>(25, 25) \n",
    "\n",
    "        if rows == 1 and cols == 1:\n",
    "            ax = axes\n",
    "        elif rows == 1:\n",
    "            ax = axes[head_index + 1]\n",
    "        elif cols == 1:\n",
    "            ax = axes[head_index + 1]\n",
    "        else:\n",
    "            ax = axes[(head_index + 1) // cols, (head_index + 1) % cols]\n",
    "\n",
    "        ax.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# def visualization(args, image_path, query_index, attention_scores, encoder_output):\n",
    "\n",
    "#     attention_score = attention_scores[5, :, :, :, :] # sixth layer of the decoder\n",
    "#     attention_score_pred_query = attention_score[:, :, query_index, :] # query corresponding to predicted class \n",
    "\n",
    "#     image = T.Resize(size=(args.image_size, args.image_size))(Image.open(image_path))\n",
    "#     img_tensor = T.ToTensor()(image)\n",
    "\n",
    "#     # Load and resize the original image\n",
    "#     input_image = cv2.imread(image_path)\n",
    "#     input_image = cv2.resize(input_image, (0, 0), fx=0.8, fy=0.8)\n",
    "\n",
    "#     # Create a subplot grid for the original image and visualizations\n",
    "#     num_heads = attention_score_pred_query.shape[1] + 1  \n",
    "#     rows = 1\n",
    "#     cols = num_heads // rows\n",
    "\n",
    "#     # Plot the original image\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "#     axes[0].imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "#     axes[0].axis('off')\n",
    "\n",
    "#     for head_index in range(attention_score_pred_query.shape[1]):\n",
    "#         heatmap_head = attention_score_pred_query[:, head_index, :].reshape(encoder_output.shape[2], encoder_output.shape[3]).detach().cpu().numpy()\n",
    "#         pdb.set_trace()\n",
    "#         result = SuperImposeHeatmap(heatmap_head, input_image) # heatmap_head-><class 'numpy.ndarray'>(25, 25) \n",
    "\n",
    "#         if rows == 1 and cols == 1:\n",
    "#             ax = axes\n",
    "#         elif rows == 1:\n",
    "#             ax = axes[head_index + 1]\n",
    "#         elif cols == 1:\n",
    "#             ax = axes[head_index + 1]\n",
    "#         else:\n",
    "#             ax = axes[(head_index + 1) // cols, (head_index + 1) % cols]\n",
    "\n",
    "#         ax.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "#         ax.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b36dae4d-277c-439c-bdf8-034938818042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In build function\n",
      "Built backbone\n",
      "Built transformer\n",
      "Built tree\n",
      "Set anc labels\n",
      "> \u001b[0;32m/tmp/ipykernel_317451/1458321408.py\u001b[0m(27)\u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     25 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m        \u001b[0mpred_class_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# print (\"Species predicted by INTR is:\",get_class_name(int(pred_class_index[0][0])+1), \"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Species predicted by HierINTR is:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_to_spcname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_class_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  type(attention_scores)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_scores.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 8, 190, 625])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_score = attention_scores[5, :, :, :, :]\n",
      "ipdb>  attention_score.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 190, 625])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  pred_class_index=predicted_class(outputs, topk=(1, 1))\n",
      "ipdb>  query_index = int(pred_class_index[0][0])\n",
      "ipdb>  query_index \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_score_pred_query = attention_score[:, :, query_index, :]\n",
      "ipdb>  attention_score_pred_query.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 625])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  head_index = 0\n",
      "ipdb>  heatmap_head = attention_score_pred_query[:, head_index, :].reshape(encoder_output.shape[2], encoder_output.shape[3]).detach().cpu().numpy()\n",
      "ipdb>  heatmap_head.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  type(heatmap_head)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    dataset_val = build_dataset(image_set=args.test, args=args)\n",
    "    label_to_spcname = {label: classname for classname, label in dataset_val.class_to_idx.items()}\n",
    "    \n",
    "    image_path = \"/home/harishbabu/data/cub190_imgnet/train/cub_012_Yellow_headed_Blackbird/Yellow_Headed_Blackbird_0017_8511.jpg\"\n",
    "    \n",
    "    test_image_loader=image_preprocessing(image_path)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "    # model, _ = build_model(args)\n",
    "    model, criterion, spclabel_to_anclabels= build_model_hierINTR(args, label_to_spcname)\n",
    "    model.to(device)\n",
    "    model=load_model(args, model)\n",
    "    model.eval()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "    for samples, targets in metric_logger.log_every(test_image_loader, 1, header):\n",
    "        samples = samples.to(device)\n",
    "    \n",
    "        outputs, encoder_output, _, attention_scores, avg_attention_scores = model(samples)\n",
    "\n",
    "        pdb.set_trace()\n",
    "        pred_class_index=predicted_class(outputs, topk=(1, 1))\n",
    "        # print (\"Species predicted by INTR is:\",get_class_name(int(pred_class_index[0][0])+1), \"\\n\")\n",
    "        print (\"Species predicted by HierINTR is:\",label_to_spcname[int(pred_class_index[0][0])], \"\\n\")\n",
    "\n",
    "        visualization(args, image_path, int(pred_class_index[0][0]), attention_scores, encoder_output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser('INTR interpretation visualization script', parents=[get_args_parser()])\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    args.phylo_config = 'configs/cub190_phylogeny_disc4.yaml'\n",
    "    args.resume = 'output_HierINTR/cub190_imgnet/001_cub190-imgnet_disc=4/cub_checkpoint.pth'\n",
    "    args.dataset_path = \"/home/harishbabu/data/\"\n",
    "    args.dataset_name = \"cub190_imgnet\"\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46145fdd-32b4-4e4e-ad27-d914a6652c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/INTR\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83701491-7e55-4d0e-8916-9f43a5d53686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
