{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e50bfe-edb9-4932-bf43-39f047bf36d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cv2 \n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "from models import build_model, build_model_hierINTR\n",
    "import datasets.transforms as T\n",
    "from datasets import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac39b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Set transformer detector', add_help=False)\n",
    "    parser.add_argument('--lr_backbone', default=1.00e-5, type=float)\n",
    "    parser.add_argument('--batch_size', default=1, type=int, choices=[1])\n",
    "\n",
    "    # * Backbone\n",
    "    parser.add_argument('--backbone', default='resnet50', type=str,\n",
    "                        help=\"Name of the convolutional backbone to use\")\n",
    "    parser.add_argument('--dilation', action='store_true',\n",
    "                        help=\"If true, we replace stride with dilation in the last convolutional block (DC5)\")\n",
    "    parser.add_argument('--position_embedding', default='sine', type=str, choices=('sine', 'learned'),\n",
    "                        help=\"Type of positional embedding to use on top of the image features\")\n",
    "    parser.add_argument('--resume', default='path/to/intr_checkpoint_cub_detr_r50.pth',\n",
    "                        help='resume from checkpoint')\n",
    "    \n",
    "    # * Transformer\n",
    "    parser.add_argument('--enc_layers', default=6, type=int,\n",
    "                        help=\"Number of encoding layers in the transformer\")\n",
    "    parser.add_argument('--dec_layers', default=6, type=int,\n",
    "                        help=\"Number of decoding layers in the transformer\")\n",
    "    parser.add_argument('--dim_feedforward', default=2048, type=int,\n",
    "                        help=\"Intermediate size of the feedforward layers in the transformer blocks\")\n",
    "    parser.add_argument('--hidden_dim', default=256, type=int,\n",
    "                        help=\"Size of the embeddings (dimension of the transformer)\")\n",
    "    parser.add_argument('--dropout', default=0.1, type=float,\n",
    "                        help=\"Dropout applied in the transformer\") #default=0.1\n",
    "    parser.add_argument('--nheads', default=8, type=int,\n",
    "                        help=\"Number of attention heads inside the transformer's attentions\")\n",
    "    parser.add_argument('--num_queries', default=200, type=int,\n",
    "                        help=\"Number of query slots\")\n",
    "    parser.add_argument('--pre_norm', action='store_true')\n",
    "\n",
    "    # # * Dataset parameters\n",
    "    parser.add_argument('--dataset_name', default='cub') \n",
    "    parser.add_argument('--dataset_path', default='/path/to/datasets', type=str) \n",
    "    parser.add_argument('--test', default=\"val\", type=str, choices=[\"val\", \"test\"])\n",
    "\n",
    "    # * Device parameters\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "\n",
    "    # Phylogeny parameters\n",
    "    parser.add_argument(\"--phylo_config\", type=str, default=None, \n",
    "                        help='path to the yaml file containing \"phylogeny_path\" and \"phyloDistances_string\"') # \"./configs/cub27_phylogeny.yaml\"\n",
    "    \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de29cac8-84f7-4464-b006-cf99e2c907ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean_std = {\n",
    "    \"cub\": (\n",
    "        torch.tensor([0.485, 0.456, 0.406]),\n",
    "        torch.tensor([0.229, 0.224, 0.225]),\n",
    "    ),\n",
    "}\n",
    "\n",
    "class SingleImageDataset:\n",
    "    def __init__(self, image_path, transform=None):\n",
    "        self.image_path = image_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_path).convert('RGB')\n",
    "\n",
    "        target = {}\n",
    "        target[\"file_name\"] = [str(self.image_path)]\n",
    "        target[\"image_label\"] = torch.tensor([0000], dtype=torch.int64)  # Set the target label as needed\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img, target = self.transform(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1  \n",
    "\n",
    "def make_transforms():\n",
    "    mean, std = data_mean_std[\"cub\"]\n",
    "\n",
    "    normalize = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std)\n",
    "    ])\n",
    "    return T.Compose([\n",
    "        T.RandomResize([800], max_size=1333),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "def build_single_image_dataset(image_path):\n",
    "    transform = make_transforms()\n",
    "    dataset = SingleImageDataset(image_path=image_path, transform=transform)\n",
    "    return dataset\n",
    "\n",
    "def image_preprocessing(image_path):\n",
    "    single_image_dataset = build_single_image_dataset(image_path)\n",
    "    sampler_val = torch.utils.data.SequentialSampler(single_image_dataset)\n",
    "    data_loader_val = DataLoader(single_image_dataset, args.batch_size, sampler=sampler_val,\n",
    "                                 drop_last=False, collate_fn=utils.collate_fn, num_workers=1) \n",
    "    return data_loader_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea43f215-9327-46ee-a623-fa10570ebc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args, model):\n",
    "    checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92960ce5-a3dd-4bbf-aa82-6612130db9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predicted_class(output, topk=(1,)):\n",
    "    query_logits = output['query_logits']\n",
    "    batch_size = query_logits.size(0)\n",
    "    \n",
    "    maxk = min(max(topk), query_logits.size(1))\n",
    "    _, pred = query_logits.topk(maxk, dim=1, largest=True, sorted=True)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e41e40-38f2-40da-aa0d-79ec5bf95b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_name(number, filename=\"demo_image/classes.txt\"):\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(\" \", 1)\n",
    "        if parts[0] == str(number):\n",
    "            class_name = parts[1]\n",
    "            break\n",
    "    else:\n",
    "        return f\"No class found for number {number}\"\n",
    "\n",
    "    class_name_parts = class_name.split(\".\")\n",
    "    modified_name = \" \".join(part.capitalize() for part in class_name_parts[1].split(\"_\"))\n",
    "\n",
    "    return modified_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b259b97d-ca36-4b89-a24b-2b9876616464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SuperImposeHeatmap(attention, input_image):\n",
    "    alpha=0.5\n",
    "    avg_heatmap_resized = cv2.resize(attention, (input_image.shape[1], input_image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "    avg_normalized_heatmap = (avg_heatmap_resized - np.min(avg_heatmap_resized)) / (np.max(avg_heatmap_resized) - np.min(avg_heatmap_resized))\n",
    "    heatmap = (avg_normalized_heatmap * 255).astype(np.uint8)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.medianBlur(heatmap,15)\n",
    "    heatmap =  cv2.GaussianBlur(heatmap, (15, 15), 0)\n",
    "    result = (input_image *alpha  + heatmap * (1-alpha)).astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "def get_heatmap(latent_activation, input_image, constant_color_scale=False):\n",
    "    image_a = latent_activation.cpu().numpy()\n",
    "    image_b = input_image.permute(1, 2, 0).cpu().numpy()\n",
    "    reshaped_image_a = np.array(Image.fromarray((image_a[0] * 255).astype('uint8')).resize((input_image.shape[-1], input_image.shape[-1])))\n",
    "    if constant_color_scale:\n",
    "        reshaped_image_a = np.concatenate((reshaped_image_a, np.zeros((reshaped_image_a.shape[1], 1)), np.ones((reshaped_image_a.shape[1], 1))*255), axis=1)\n",
    "    \n",
    "    normalized_heatmap = (reshaped_image_a - np.min(reshaped_image_a)) / (np.max(reshaped_image_a) - np.min(reshaped_image_a))\n",
    "    heatmap_colormap = plt.get_cmap('jet')\n",
    "    heatmap_colored = heatmap_colormap(normalized_heatmap)\n",
    "\n",
    "    if constant_color_scale:\n",
    "        heatmap_colored = heatmap_colored[:, :-2]\n",
    "    \n",
    "    heatmap_colored_uint8 = (heatmap_colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    image_a_heatmap_pillow = Image.fromarray(heatmap_colored_uint8)\n",
    "    image_b_pillow = Image.fromarray((image_b * 255).astype('uint8'))\n",
    "    \n",
    "    result_image = Image.blend(image_b_pillow, image_a_heatmap_pillow, alpha=0.3)\n",
    "    \n",
    "    return np.array(result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b39c060-1170-4802-933e-d53465cebf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pdb\n",
    "\n",
    "def visualization(args, image_path, query_index, attention_scores, encoder_output):\n",
    "\n",
    "    attention_score = attention_scores[5, :, :, :, :] # sixth layer of the decoder\n",
    "    attention_score_pred_query = attention_score[:, :, query_index, :] # query corresponding to predicted class \n",
    "\n",
    "    # Load and resize the original image\n",
    "    input_image = cv2.imread(image_path)\n",
    "    input_image = cv2.resize(input_image, (0, 0), fx=0.8, fy=0.8)\n",
    "\n",
    "    # Create a subplot grid for the original image and visualizations\n",
    "    num_heads = attention_score_pred_query.shape[1] + 1  \n",
    "    rows = 1\n",
    "    cols = num_heads // rows\n",
    "\n",
    "    # Plot the original image\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "    axes[0].imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for head_index in range(attention_score_pred_query.shape[1]):\n",
    "        heatmap_head = attention_score_pred_query[:, head_index, :].reshape(encoder_output.shape[2], encoder_output.shape[3]).detach().cpu().numpy()\n",
    "        result = SuperImposeHeatmap(heatmap_head, input_image) # heatmap_head-><class 'numpy.ndarray'>(25, 25) \n",
    "\n",
    "        if rows == 1 and cols == 1:\n",
    "            ax = axes\n",
    "        elif rows == 1:\n",
    "            ax = axes[head_index + 1]\n",
    "        elif cols == 1:\n",
    "            ax = axes[head_index + 1]\n",
    "        else:\n",
    "            ax = axes[(head_index + 1) // cols, (head_index + 1) % cols]\n",
    "\n",
    "        ax.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualization(args, image_path, query_index, attention_scores, encoder_output):\n",
    "\n",
    "    attention_score = attention_scores[5, :, :, :, :] # sixth layer of the decoder\n",
    "    attention_score_pred_query = attention_score[:, :, query_index, :] # query corresponding to predicted class \n",
    "\n",
    "    image = T.Resize(size=(args.image_size, args.image_size))(Image.open(image_path))\n",
    "    img_tensor = T.ToTensor()(image)\n",
    "\n",
    "    # Load and resize the original image\n",
    "    input_image = cv2.imread(image_path)\n",
    "    input_image = cv2.resize(input_image, (0, 0), fx=0.8, fy=0.8)\n",
    "\n",
    "    # Create a subplot grid for the original image and visualizations\n",
    "    num_heads = attention_score_pred_query.shape[1] + 1  \n",
    "    rows = 1\n",
    "    cols = num_heads // rows\n",
    "\n",
    "    # Plot the original image\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "    axes[0].imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for head_index in range(attention_score_pred_query.shape[1]):\n",
    "        heatmap_head = attention_score_pred_query[:, head_index, :].reshape(encoder_output.shape[2], encoder_output.shape[3]).detach().cpu().numpy()\n",
    "        # get_heatmap(latent_activation, input_image\n",
    "        result = SuperImposeHeatmap(heatmap_head, input_image) # heatmap_head-><class 'numpy.ndarray'>(25, 25) \n",
    "\n",
    "        if rows == 1 and cols == 1:\n",
    "            ax = axes\n",
    "        elif rows == 1:\n",
    "            ax = axes[head_index + 1]\n",
    "        elif cols == 1:\n",
    "            ax = axes[head_index + 1]\n",
    "        else:\n",
    "            ax = axes[(head_index + 1) // cols, (head_index + 1) % cols]\n",
    "\n",
    "        ax.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36dae4d-277c-439c-bdf8-034938818042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In build function\n",
      "Built backbone\n",
      "Built transformer\n",
      "Built tree\n",
      "Set anc labels\n",
      "Species predicted by HierINTR is: cub_012_Yellow_headed_Blackbird \n",
      "\n",
      "Test:  [0/1]  eta: 0:00:00    time: 0.3410  data: 0.2466  max mem: 2172\n",
      "Test: Total time: 0:00:00 (0.4159 s / it)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 8, 190, 625])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_score = attention_scores[5, :, :, :, :]\n",
      "ipdb>  attention_score.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 190, 625])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  pred_class_index=predicted_class(outputs, topk=(1, 1))\n",
      "ipdb>  query_index = int(pred_class_index[0][0])\n",
      "ipdb>  query_index \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  attention_score_pred_query = attention_score[:, :, query_index, :]\n",
      "ipdb>  attention_score_pred_query.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 625])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  head_index = 0\n",
      "ipdb>  heatmap_head = attention_score_pred_query[:, head_index, :].reshape(encoder_output.shape[2], encoder_output.shape[3]).detach().cpu().numpy()\n",
      "ipdb>  heatmap_head.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 25)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  type(heatmap_head)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    dataset_val = build_dataset(image_set=args.test, args=args)\n",
    "    label_to_spcname = {label: classname for classname, label in dataset_val.class_to_idx.items()}\n",
    "    \n",
    "    image_path = \"/home/harishbabu/data/cub190_imgnet/train/cub_012_Yellow_headed_Blackbird/Yellow_Headed_Blackbird_0017_8511.jpg\"\n",
    "    \n",
    "    test_image_loader=image_preprocessing(image_path)\n",
    "\n",
    "    device = torch.device(args.device)\n",
    "    # model, _ = build_model(args)\n",
    "    model, criterion, spclabel_to_anclabels= build_model_hierINTR(args, label_to_spcname)\n",
    "    model.to(device)\n",
    "    model=load_model(args, model)\n",
    "    model.eval()\n",
    "\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    header = 'Test:'\n",
    "    for samples, targets in metric_logger.log_every(test_image_loader, 1, header):\n",
    "        samples = samples.to(device)\n",
    "    \n",
    "        outputs, encoder_output, _, attention_scores, avg_attention_scores = model(samples)\n",
    "\n",
    "        pred_class_index=predicted_class(outputs, topk=(1, 1))\n",
    "        # print (\"Species predicted by INTR is:\",get_class_name(int(pred_class_index[0][0])+1), \"\\n\")\n",
    "        print (\"Species predicted by HierINTR is:\",label_to_spcname[int(pred_class_index[0][0])], \"\\n\")\n",
    "\n",
    "        # visualization(args, image_path, int(pred_class_index[0][0]), attention_scores, encoder_output)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser('INTR interpretation visualization script', parents=[get_args_parser()])\n",
    "    args = parser.parse_args(args=[])\n",
    "\n",
    "    args.phylo_config = 'configs/cub190_phylogeny_disc4.yaml'\n",
    "    args.resume = 'output_HierINTR/cub190_imgnet/001_cub190-imgnet_disc=4/cub_checkpoint.pth'\n",
    "    args.dataset_path = \"/home/harishbabu/data/\"\n",
    "    args.dataset_name = \"cub190_imgnet\"\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46145fdd-32b4-4e4e-ad27-d914a6652c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/projects/INTR\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f9d7be-9d7b-4528-9485-0cb5cd1b7757",
   "metadata": {},
   "source": [
    "# Knock-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faaaa712-6db9-4174-b287-bd77d1638de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In build function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/harishbabu/.conda/envs/hpnet4/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /home/harishbabu/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 101MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built backbone\n",
      "Built transformer\n",
      "Built tree\n",
      "Set anc labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HierINTR(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (presence_vector): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (query_embed_anc): ModuleDict(\n",
       "    (0): Embedding(16, 64)\n",
       "    (1): Embedding(39, 64)\n",
       "    (2): Embedding(90, 64)\n",
       "  )\n",
       "  (query_embed_spc): Embedding(190, 64)\n",
       "  (input_proj): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (backbone): Joiner(\n",
       "    (0): Backbone(\n",
       "      (body): IntermediateLayerGetter(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): FrozenBatchNorm2d()\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PositionEmbeddingSine()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('INTR interpretation visualization script', parents=[get_args_parser()])\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.phylo_config = 'configs/cub190_phylogeny_disc4.yaml'\n",
    "args.resume = 'output_HierINTR/cub190_imgnet/001_cub190-imgnet_disc=4/cub_checkpoint.pth'\n",
    "args.dataset_path = \"/home/harishbabu/data/\"\n",
    "args.dataset_name = \"cub190_imgnet\"\n",
    "\n",
    "dataset_val = build_dataset(image_set=args.test, args=args)\n",
    "spcname_to_label = dataset_val.class_to_idx\n",
    "label_to_spcname = {label: classname for classname, label in dataset_val.class_to_idx.items()}\n",
    "\n",
    "image_path = \"/home/harishbabu/data/cub190_imgnet/train/cub_012_Yellow_headed_Blackbird/Yellow_Headed_Blackbird_0017_8511.jpg\"\n",
    "\n",
    "test_image_loader=image_preprocessing(image_path)\n",
    "\n",
    "device = torch.device(args.device)\n",
    "# model, _ = build_model(args)\n",
    "model, criterion, spclabel_to_anclabels= build_model_hierINTR(args, label_to_spcname)\n",
    "model.to(device)\n",
    "model=load_model(args, model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a167b4f2-2a94-42fb-bcd4-0edd5fefa0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spcname_to_label['cub_012_Yellow_headed_Blackbird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be92335f-9067-447e-8302-b2644815bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.spclabel_to_anclabels\n",
    "# spcname_to_label\n",
    "\n",
    "def get_lvl_cousins(level, spclabel, spclabel_to_anclabels):\n",
    "    # return the labels of cousins at a particular level\n",
    "\n",
    "    assert level < len(list(spclabel_to_anclabels.values())[0])\n",
    "    species_level_label = spclabel_to_anclabels[spclabel][level]\n",
    "    return [cousin_spclabel for cousin_spclabel, anclabels in spclabel_to_anclabels.items() \\\n",
    "             if ((anclabels[level] == species_level_label) and (cousin_spclabel != spclabel))]\n",
    "    \n",
    "cousin_labels = get_lvl_cousins(level=1, spclabel=11, spclabel_to_anclabels=model.spclabel_to_anclabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7c2ab9-b743-4e23-9024-4c25dcadcdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 20,\n",
       " 24,\n",
       " 25,\n",
       " 46,\n",
       " 72,\n",
       " 84,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 138]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cousin_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c83695ee-3b70-40ca-bc89-f4a736ae7681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 0, 0],\n",
       " 1: [0, 0, 0],\n",
       " 2: [0, 0, 0],\n",
       " 3: [1, 2, 2],\n",
       " 4: [2, 4, 5],\n",
       " 5: [2, 4, 5],\n",
       " 6: [2, 4, 5],\n",
       " 7: [2, 4, 6],\n",
       " 8: [3, 6, 13],\n",
       " 9: [3, 6, 14],\n",
       " 10: [3, 6, 13],\n",
       " 11: [3, 6, 15],\n",
       " 12: [3, 6, 15],\n",
       " 13: [3, 7, 26],\n",
       " 14: [3, 7, 27],\n",
       " 15: [3, 7, 27],\n",
       " 16: [3, 8, 29],\n",
       " 17: [4, 15, 47],\n",
       " 18: [5, 16, 48],\n",
       " 19: [3, 9, 31],\n",
       " 20: [3, 6, 16],\n",
       " 21: [6, 20, 58],\n",
       " 22: [6, 20, 58],\n",
       " 23: [6, 20, 58],\n",
       " 24: [3, 6, 14],\n",
       " 25: [3, 6, 14],\n",
       " 26: [5, 17, 51],\n",
       " 27: [7, 21, 60],\n",
       " 28: [7, 21, 61],\n",
       " 29: [1, 3, 3],\n",
       " 30: [1, 3, 4],\n",
       " 31: [1, 3, 3],\n",
       " 32: [3, 10, 41],\n",
       " 33: [3, 10, 41],\n",
       " 34: [8, 24, 67],\n",
       " 35: [9, 28, 74],\n",
       " 36: [9, 29, 78],\n",
       " 37: [9, 28, 75],\n",
       " 38: [9, 28, 76],\n",
       " 39: [9, 29, 78],\n",
       " 40: [9, 28, 77],\n",
       " 41: [9, 28, 75],\n",
       " 42: [0, 1, 1],\n",
       " 43: [10, 30, 79],\n",
       " 44: [3, 11, 43],\n",
       " 45: [3, 11, 43],\n",
       " 46: [3, 6, 13],\n",
       " 47: [11, 31, 80],\n",
       " 48: [11, 31, 80],\n",
       " 49: [11, 32, 81],\n",
       " 50: [11, 33, 82],\n",
       " 51: [3, 7, 27],\n",
       " 52: [3, 12, 44],\n",
       " 53: [3, 10, 42],\n",
       " 54: [3, 7, 28],\n",
       " 55: [2, 4, 7],\n",
       " 56: [2, 5, 9],\n",
       " 57: [2, 5, 9],\n",
       " 58: [2, 5, 9],\n",
       " 59: [2, 5, 9],\n",
       " 60: [2, 5, 9],\n",
       " 61: [2, 5, 9],\n",
       " 62: [2, 5, 9],\n",
       " 63: [2, 5, 9],\n",
       " 64: [12, 34, 83],\n",
       " 65: [12, 34, 83],\n",
       " 66: [12, 34, 83],\n",
       " 67: [12, 34, 84],\n",
       " 68: [2, 4, 8],\n",
       " 69: [2, 4, 8],\n",
       " 70: [7, 21, 62],\n",
       " 71: [7, 21, 62],\n",
       " 72: [3, 6, 17],\n",
       " 73: [9, 29, 78],\n",
       " 74: [9, 29, 78],\n",
       " 75: [8, 25, 71],\n",
       " 76: [8, 26, 72],\n",
       " 77: [8, 26, 72],\n",
       " 78: [8, 25, 71],\n",
       " 79: [8, 27, 73],\n",
       " 80: [2, 5, 9],\n",
       " 81: [13, 35, 85],\n",
       " 82: [14, 37, 88],\n",
       " 83: [10, 30, 79],\n",
       " 84: [3, 6, 18],\n",
       " 85: [10, 30, 79],\n",
       " 86: [10, 30, 79],\n",
       " 87: [5, 16, 49],\n",
       " 88: [7, 21, 63],\n",
       " 89: [5, 18, 52],\n",
       " 90: [3, 6, 19],\n",
       " 91: [3, 6, 20],\n",
       " 92: [3, 6, 20],\n",
       " 93: [3, 6, 19],\n",
       " 94: [3, 9, 32],\n",
       " 95: [6, 20, 59],\n",
       " 96: [6, 20, 59],\n",
       " 97: [9, 28, 76],\n",
       " 98: [3, 13, 45],\n",
       " 99: [2, 4, 6],\n",
       " 100: [7, 21, 60],\n",
       " 101: [7, 21, 60],\n",
       " 102: [3, 9, 33],\n",
       " 103: [7, 22, 64],\n",
       " 104: [7, 22, 64],\n",
       " 105: [3, 6, 21],\n",
       " 106: [3, 6, 22],\n",
       " 107: [3, 6, 22],\n",
       " 108: [3, 6, 22],\n",
       " 109: [3, 6, 22],\n",
       " 110: [3, 14, 46],\n",
       " 111: [3, 6, 22],\n",
       " 112: [3, 6, 23],\n",
       " 113: [3, 6, 24],\n",
       " 114: [3, 6, 17],\n",
       " 115: [3, 6, 21],\n",
       " 116: [3, 6, 25],\n",
       " 117: [3, 6, 21],\n",
       " 118: [3, 6, 25],\n",
       " 119: [3, 6, 21],\n",
       " 120: [3, 6, 25],\n",
       " 121: [3, 6, 21],\n",
       " 122: [3, 6, 23],\n",
       " 123: [3, 6, 25],\n",
       " 124: [3, 6, 17],\n",
       " 125: [3, 6, 17],\n",
       " 126: [13, 36, 86],\n",
       " 127: [13, 36, 86],\n",
       " 128: [13, 36, 87],\n",
       " 129: [3, 8, 30],\n",
       " 130: [3, 8, 30],\n",
       " 131: [2, 5, 10],\n",
       " 132: [2, 5, 10],\n",
       " 133: [2, 5, 11],\n",
       " 134: [2, 5, 10],\n",
       " 135: [2, 5, 10],\n",
       " 136: [2, 5, 10],\n",
       " 137: [2, 5, 12],\n",
       " 138: [3, 6, 16],\n",
       " 139: [5, 16, 50],\n",
       " 140: [5, 16, 49],\n",
       " 141: [7, 23, 65],\n",
       " 142: [7, 23, 65],\n",
       " 143: [7, 23, 66],\n",
       " 144: [7, 23, 66],\n",
       " 145: [7, 23, 66],\n",
       " 146: [7, 23, 65],\n",
       " 147: [7, 23, 65],\n",
       " 148: [3, 9, 33],\n",
       " 149: [3, 9, 34],\n",
       " 150: [3, 9, 33],\n",
       " 151: [3, 9, 35],\n",
       " 152: [3, 9, 36],\n",
       " 153: [3, 9, 33],\n",
       " 154: [3, 9, 33],\n",
       " 155: [3, 9, 33],\n",
       " 156: [3, 9, 35],\n",
       " 157: [3, 9, 37],\n",
       " 158: [3, 9, 38],\n",
       " 159: [3, 9, 33],\n",
       " 160: [3, 9, 38],\n",
       " 161: [3, 9, 35],\n",
       " 162: [3, 9, 35],\n",
       " 163: [3, 9, 33],\n",
       " 164: [3, 9, 33],\n",
       " 165: [3, 9, 33],\n",
       " 166: [3, 9, 39],\n",
       " 167: [3, 9, 39],\n",
       " 168: [3, 9, 35],\n",
       " 169: [3, 9, 36],\n",
       " 170: [3, 9, 40],\n",
       " 171: [3, 9, 33],\n",
       " 172: [3, 9, 34],\n",
       " 173: [3, 9, 34],\n",
       " 174: [15, 38, 89],\n",
       " 175: [15, 38, 89],\n",
       " 176: [8, 24, 68],\n",
       " 177: [8, 24, 67],\n",
       " 178: [8, 24, 69],\n",
       " 179: [8, 24, 70],\n",
       " 180: [8, 24, 69],\n",
       " 181: [8, 24, 70],\n",
       " 182: [5, 19, 53],\n",
       " 183: [5, 19, 54],\n",
       " 184: [5, 19, 53],\n",
       " 185: [5, 19, 55],\n",
       " 186: [5, 19, 56],\n",
       " 187: [5, 19, 57],\n",
       " 188: [5, 19, 55],\n",
       " 189: [3, 9, 38]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.spclabel_to_anclabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11faa27c-7a2d-4843-be58-6aba817c59b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
